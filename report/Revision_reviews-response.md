

| TODO | Reviewer | Comment | Response | Issue |
| ----- | ----- | ----- | ----- | ----- |
|  | 1 | make better use of the result figures and tables, and incorporate subheadings to better guide readers to different aspects of the results | Accept \- Restructure results section with clear subheadings (e.g., 'Model characteristics', 'Descriptive performance trends', 'Adjusted model estimates'). Explicitly reference figures/tables when introducing each result subsection. | #100 |
|  | 1 | including the regression formula for GAMM in the main text | Accept \- Add formal mathematical notation of the GAMM formula in Methods section, showing the full model with all terms (fixed effects, random effects, smoothing terms). | #101 |
|  | 1 | do another round on the language used for fixed/random effects/explanatory variables/covariates and standardise the terms throughout the text | Accept \- Conduct systematic review of terminology. Use: 'explanatory variables' for overall, 'random effects' for grouping factors in GAMM, 'smooth terms' for splines. Create glossary for revision tracking. | #101 |
| X | 1 | random effect for location+time is effectively 'it's always hard/easy at this place at this time', but provides no further insight to what makes it hard or easy. Maybe instead of a spline of time with fixed knots \= 40, you could discretely divide time into phases dominated by different circulating strains | Accept | #102 |
|  | 1 | I'm in general curious why using an additive model with smoothing splines. Intuitively I would expect most of the modelled effects to have fairly simple relationships with predictability | Accept \- Add justification in Methods explaining: (1) horizon effects likely non-linear, (2) time trends within countries are complex, (3) GAMMs allow data to determine functional form rather than imposing parametric assumptions, (4) model diagnostics support approach. | #103 |
|  | 1 | Shouldn't the effect of model and methods be hierarchical, since each model is assigned to a class of methods? | Partly accept \- The current specification does create method-specific model effects (models nested within methods). Add clarifying text explaining this is effectively hierarchical. Consider sensitivity analysis with fully nested random effects if computationally feasible. | #104 |
|  | 1 | a better narrative is to say you must adjust for confounding factors to be able to compare forecast performance of your sampled models, thus the GAMM approach is necessary | Accept \- Revise Introduction/Methods to emphasize that comparisons across diverse targets/times REQUIRE adjustment. Highlight that unadjusted comparisons are misleading due to confounding. Frame GAMM as essential rather than optional enhancement. | #105 |
|  | **1** | **Are there any models with sub-national forecast targets? Related, did you find any effect of country population size on WIS among single-country models?** | Accept \- Add statement in Methods/Results that no sub-national targets exist in dataset. For population size: conduct supplementary analysis or acknowledge as limitation if no signal found. | #106 |
| X | 1 | I think you need to more thoroughly justify why only evaluate with WIS as opposed to or in addition to eg CRPS | Accept \- Add justification in Methods: WIS is proper scoring rule for interval forecasts, matches the quantile forecast format teams submitted, and allows log transformation.  | #107 |
|  | 1 | Presumably all forecast intervals are for negatively binomial distributed count data (cases or death)? Please explicitly state this | Partly accept \- Clarified that observations are of count data (incident cases/deaths) although quantile forecasts don't require teams to specify distributional assumptions. Observations are counts; forecasts are quantile predictions. | #108 |
|  | 1 | Why log link in the GAMM? Since WIS is already calculated on log scale, it's not intuitive to me why the modelled effects are expected to be multiplicative | Accept \- Add justification: log-link accounts for right-skew in WIS distribution, ensures positive predictions, and multiplicative effects are interpretable as proportional changes in score. Alternatively, could re-run with identity link as sensitivity check. | #109 |
|  | 1 | In the QQ plot in your supp results it looks like dispersion of WIS score in the fitted GAMM is a bit off? | Accept \- Examine QQ plots carefully. If concerning: (1) try alternative link function or error distribution, (2) acknowledge limitation explicitly in Methods/Discussion, (3) note that point estimates may be robust even if uncertainty estimates are affected. | #110 |
|  | 1 | it is vague that by model structure you mean mechanistic vs statistical etc, and by forecast target you mean single vs multi country. I think you need to word this sentence to more accurately reflect the language used later on | Accept \- Revise abstract to specify 'model structure (agent-based, mechanistic, semi-mechanistic, statistical)' and 'geographic specificity (single versus multiple countries)'. | #111 |
|  | 1 | I think it's worth expanding this paragraph to also point out that different models are by design meant to be good at different things | Accept \- Add 2-3 sentences to paragraph around line 69 noting that models serve multiple purposes, forecasting is one use case, and structural differences may be optimized for different objectives. | #112 |
|  | 1 | I'm not fully convinced that target-specificity is necessarily linked to how many target countries the model predicts to | Partly accept \- Acknowledge this limitation in Discussion. Clarify that we use number of targets as a PROXY for specificity, but recognize it's imperfect. Note that we lack data on actual model customization practices. Soften claims about 'specificity' vs 'number of targets'. | #113 |
|  | 1 | if you analyse forecast performance only among models submitted to the same round of forecast for the same target, you do not need to model confounding factorsâ€¦ I think a stronger narrative is that post-hoc modelling of forecast performance enables you to compare across targets and time periods | Accept \- Revise lines 98-101 to emphasize that GAMM approach enables comparisons across all targets/times/models simultaneously, which wouldn't be possible with stratified analyses. This is a strength not just a necessity. | #114 |
| X | 1 | are all 'others' model expert judgement based? Why not just call them expert-judged? | Accept \- Change 'Other' to 'Expert judgment' or 'Human judgment' throughout manuscript and in Supplementary Table 1\. | #115 |
|  | 1 | give package and R version numbers | Accept \- Add R version and key package versions (mgcv, dplyr, ggplot2, etc.) to Methods section. Can extract from sessionInfo() if available in output files. | #116 |
|  | **1** | **I find forecastsMean column unnecessary, it doesn't show anything useful (and the sum doesn't make sense). You also need to explicitly explain what the numbers in brackets are** | Accept \- Remove 'Mean forecasts' column from Table 1\. Add footnote or caption text explaining that numbers in brackets are standard deviations for Mean WIS column. | #117 |
|  | **1** | **If someone has just seen the figure without thoroughly reading the text, they might arrive at the conclusion agent-based models are generally better, or than single country models are better, which are not the case. I wonder if these descriptive visualisations of WIS are necessary** | Partly accept \- Keep Figure 1 (shows data characteristics) but add prominent caption note: 'Unadjusted means shown; adjusted estimates in Figure 2 show minimal differences between model types.' Could also consider moving to supplement or adding visual annotation about confounding. | #118 |
|  | **1** | **I also suggest making the colour scheme more distinct between panels A and B. I also think panel C is unnecessary** | Partly accept \- Change color schemes so A and B are clearly distinct. Consider moving panel C to supplement rather than removing, as it provides epidemiological context. | #118 |
|  | 1 | I think you need to highlight the observation about ensembling more | Accept \- Add or enhance dedicated paragraph on ensembling implications, potentially moving earlier in Discussion. Reference prior Hub work more prominently. | #119 |
|  | 1 | or maybe single-country models perform better because multi-country models are fitted to data from different ongoing epidemics, and their shared or hierarchical parameters may simply be not as well calibrated for a specific country | Accept \- Add this alternative explanation to Discussion paragraph around line 295\. Note that we can't distinguish between bespoke features reflecting expert judgement, vs. training data advantages, with current metadata. | #120 |
|  | 1 | there is value in evaluating forecasts on the go as soon as you have data, so that you can retrospectively evaluate again in the future and understand the impact of reporting errors and corrections in the data | Accept \- Add sentence to Discussion around line 303 noting value of evaluating with real-time data as well as retrospective data to understand data revision impacts. | #121 |
|  | 1 | I actually think the focus on just WIS over 4-weeks is a strength of this work | Accept \- Revise Discussion to frame focused scope (4-week, WIS) as strength rather than limitation. Emphasize that clear research question drove these choices. | #122 |
| X | 1 | you can look into this if you fitted discrete time effect of different epidemic phases dominated by different variants | Accept \- Add to future work/limitations: variant-specific phases could be explored in future analyses with appropriate phase definitions. | #123 |
| X | 2.1 | Model could be included within the main manuscript (As Plos Computational Biology format allows this), that would help the reader to follow the manuscript. A detailed description is also required | Duplicate of 1.2 | #124 |
| X | 2.2 | How was the 'Model adjustment' performed? Make a detailed discussion about adjusted and non-adjusted scenarios with the corresponding model | Accept \- This reflects comment 1.3, which we have addressed with more consistent language throughout and a clearer explanation in Methods: unadjusted \= univariate models with single predictor; adjusted \= full GAMM with all covariates. Partial effects from the full model represent 'adjusted' estimates. | #124 |
|  | **2.3** | **Figure 3 is not properly described in the manuscript. Probably, 'Multi-country' is missing in the legend** | Accept \- Review Figure 3 legend and caption. If 'Multi-country' label is missing, add it. Ensure caption clearly explains what is shown (partial effects by individual model). | #125 |
| X | 2.4 | It is advisable to improve the model or consider additional features | Partly accept \- We acknowledge model limitations in the Results and Discussion, for example noting substantial unexplained variance (e.g. figure 3). Alternative model specification (e.g. an identity link function, different feature selection) does not provide substantially different results, suggesting the direction of estimates is robust despite the poor fit. We emphasise that this work is exploratory and aim to further identify appropriate models for comparative evaluation in future. | #126 |
| X | 2.5 | Authors are advised to include ensemble model within the study as it often gives better results in epidemic forecasting | Reject \- Hub ensemble models are constructed from the contributed models, whereas in this work we are investigating the variation in performance among independent models. We note in Discussion that ensembles outperform and believe this has been well considered elsewhere. | #127 |
| X | 3.1 | In the author summary perhaps a rewording about it being a large dataset. I agree it is large however, it was not large in the way needed to show the differences desired | Accept \- wording of Author summary has been revised | #128 |
| X | 3.2 | It is not clear from the method of deciding the model classification whether both KS and SF processed all the files on the first pass | Accept \- Clarify the procedure: all models classified by 3+ investigators independently, then SF and KS reviewed all classifications together to resolve. Make the sequence clearer. | #129 |
| X | 3.3 | It would be of interest to know where the disagreements existed was it spread across different classifications or was it mainly between a select two | Accepted \- We have added text to the main results describing this, and a supplementary table describing the full set of classifications among reviewers. | #130 |
|  | **3.4** | **I wonder if in the supplement it could be included the results on the natural scale given it appears some of the work has been done** | Accept \- Add supplementary figure/table showing results on natural scale, with note explaining differences from log-scale results (especially for semi-mechanistic models). | #131 |
|  | 3.5 | I wonder whether any models modelled multiple countries at once or whether all models that were multi country modelled them independently. This distinction seems of interest | Partly accept \- Acknowledge we don't have detailed metadata on this. Add sentence noting this limitation and that it could explain some of the single vs multi-country differences. Suggest as future metadata to collect. | #132 |
|  | 3.6 | is there something that can be learned or improved in the metadata files. I think it would be nice if the authors could describe the current issues and where effort can be made | Accept \- Add paragraph in Discussion with specific metadata recommendations based on this analysis: (1) clearer model structure descriptions, (2) documentation of model updates/changes, (3) target-specific customizations, (4) computational resources, (5) hierarchical structure for multi-location models. | #133 |
|  | Editor | We ask that a manuscript source file is provided at Revision. Please upload your manuscript file as a .doc, .docx, .rtf or .tex | Accept \- Ensure manuscript is uploaded in appropriate format (currently .docx which is acceptable). | #134 |
|  | Editor | Please upload all main figures as separate Figure files in .tif or .eps format | Accept \- Convert figures from current format to .tif or .eps and upload separately. | #135 |
| X | Editor | Please upload a copy of Figure figures S4 and S5 which you refer to in your text on pages 8, and 24\. Or, if the figure is no longer to be included as part of the submission please remove all reference to it within the text | Accept \- Check if S4 and S5 exist (model diagnostics). If they exist, include them. If not, check what generates them (model-wis.R saves diagnostic plots) and ensure they're included, or remove references. | #136 |

